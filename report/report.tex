\documentclass{article}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage[colorlinks=true, pdfstartview=FitV, linkcolor=blue,citecolor=blue, urlcolor=blue]{hyperref}

\author{Muhammad Iqbal Tawakal}
\title{Improving image classification with CNNs by exploiting selectivity in search \& training data\\Progress report}

\begin{document}

\maketitle

\subsection*{changelog}
10 November 2014: Update the pre-trained result. \\
27 October 2014: First selective search result. \\
13 October 2014: First pre-trained result. \\
23 September 2014: First baseline result.

\section{Introduction}
The problem we will tackle in this project is image
classification. Given an image, predict a set of labels (from a
pre-defined list) that correspond to the objects in the image. This multi-class classification problem is typically solved using a set of binary classifiers. Each classifier predicts the presence or absence of a particular object. We will use the Image Classification Competition dataset from \href{http://pascallin.ecs.soton.ac.uk/challenges/VOC/}{PASCAL Visual Object Classes datasets} to assess the classifiers we develop. This particular classifier that we develop wil use the feature extracted from a convolutional neural network (CNN). We will try to improve the performance by using selective search region proposal.

There are three main experiments (currently) performed with results reported in this report.
First is baseline experiment, using CNN features extracted then performed training and testing with linear SVM.
The second is by using the pre-trained model from previous experiment on whole image, we classify regions proposed from testing dataset using selective search algorithm.
The third is we train the model from the ground up using regions proposed by selective search and also test it using the image patches from region proposal algorithm.

\section{Baseline result: Full image training + Full image testing}
This is the result of using CNN features for PASCAL VOC 2007 image classification. This result is computed by using features extracted from layer number 7 (the second fully-connected layer), 16 jittered images, and trained using SVM with penalty parameter $C$ set to 1.6. This result somewhat comparable to the one reported on \cite{alicvpr2014}.
\begin{table}[ht]
\centerline{
	\begin{tabular}{c c}
	class & layer 7 \\
	\hline
	aero & 87.5 \\
	bike & 81.0 \\
	bird & 84.4 \\
	boat & 83.7 \\
	bottle & 43.7 \\
	bus & 70.8 \\
	car & 84.6 \\
	cat & 82.8 \\
	chair & 60.6 \\
	cow & 66.7 \\
	table & 65.7 \\
	dog & 79.5 \\
	horse & 84.7 \\
	mbike & 77.2 \\
	person & 91.5 \\
	plant & 53.2 \\
	sheep & 73.3 \\
	sofa & 66.8 \\
	train & 87.7 \\
	tv & 71.7 \\
	\hline
	mAP & 74.9 \\
	\hline
	\end{tabular}
	}
	\label{tab:baseline}
	\caption{Baseline Result average precision}
\end{table}

Figure \ref{fig:pre_rec_base} shows the precision recall curve.
\begin{figure}[H]
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/1_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/2_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/3_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/4_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/5_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/6_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/7_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/8_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/9_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/10_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/11_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/12_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/13_5.png}
	\end{subfigure}
	\begin{subfigure}[h]{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/14_5.png}
	\end{subfigure}
	\begin{subfigure}{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/15_5.png}
	\end{subfigure}
	\begin{subfigure}{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/16_5.png}
	\end{subfigure}
	\begin{subfigure}{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/17_5.png}
	\end{subfigure}
	\begin{subfigure}{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/18_5.png}
	\end{subfigure}
	\begin{subfigure}{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/19_5.png}
	\end{subfigure}
	\begin{subfigure}{0.15\textwidth}
		\includegraphics[width=\textwidth]{../plot/20_5.png}
	\end{subfigure}
	\caption{Precision-Recall Curve for all classes}
	\label{fig:pre_rec_base}
\end{figure}

\section{Pre-trained model result: Full image training + segmented image testing}

Each of the testing images from PASCAL VOC 2007 dataset (all 4952 images) produces around 200-300 regions. The regions proposal are produced using selective search algorithm \cite{uijlings2013}. The parameter for initial segmentation is $k=200$ and the similarity measures used for hierarchical grouping are C+T+S+F (Color, Texture, Size, and Fill) and T+S+F. The color space used is HSV. Each region is then warped to fit the size of the CNN input by simply resize/warp to 227x227. In the R-CNN work \cite{girshick2013}, other strategies are tightest squares with context and without context.

Each region is then having its CNN features computed which produced a feature vectors with 4096 dimensions. Each feature vector is then predicted using SVM with pre-trained model from the training images. The decision results are aggregated using two different strategies. The first strategy is to average the decision value and the second strategy is simply pick the maximum value. This result is coming from $C=0.4$ and $C=0.8$ for average and max strategy, respectively.

Higher number of proposal per images (which will yield higher recall) can be achieved by using the combination of similarity measures, color space, and threshold.

\begin{table}[h]
\centerline{    
	\begin{tabular}{l c c c}
       	\hline
        Class & Baseline result & average & max \\
        \hline
		aero & 87.5 & 52.2 & 57.8 \\
		bike & 81.0 & 45.7 & 72.7 \\
		bird & 84.4 & 33.3 & 47.2 \\
		boat & 83.7 & 25.2 & 49.0 \\
		bottle & 43.6 & 29.8 & 40.9 \\
		bus & 70.9 & 35.2 & 62.6 \\
		car & 84.1 & 69.6 & 83.2 \\
		cat & 82.8 & 44.8 & 71.9 \\
		chair & 61.3 & 42.0 & 55.2 \\
		cow & 66.2 & 33.0 & 45.68 \\
		table & 66.5 & 29.5 & 59.5 \\
		dog & 79.4 & 49.0 & 65.2 \\
		horse & 84.9 & 20.5 & 42.6 \\
		mbike & 77.1 & 36.0 & 72.4 \\
		person & 91.7 & 77.9 & 90.0 \\
		plant & 54.2 & 20.7 & 34.2 \\
		sheep & 73.3 & 32.4 & 59.7 \\
		sofa & 66.6 & 35.2 & 64.7 \\
		train & 87.4 & 56.6 & 74.6 \\
		tv & 71.4 & 44.2 & 63.8 \\
		\hline
		mAP & 74.9 & 40.7 & 60.6
    \end{tabular}
}
\caption{Pre-trained model average precision [OLD]}
\end{table}

UPDATED:
The last experiment only used one color channel in the image. The updated result shows better performance. The number of regions are also increased to 2.1 million by changing the variable $k$ to 100 for the selective search algorithm.

\begin{table}[ht]
\centerline{
	\begin{tabular}{l c c}
	class & baseline & pre-trained \\
	\hline
	aero & 87.5 & 66.3 \\
	bike & 81.0 & 79.1 \\
	bird & 84.4 & 60.9 \\
	boat & 83.7 & 65.7 \\
	bottle & 43.7 & 44.5 \\
	bus & 70.8 & 68.9 \\
	car & 84.6 & 85.9 \\
	cat & 82.8 & 77.5 \\
	chair & 60.6 & 58.2 \\
	cow & 66.7 & 55.8 \\
	table & 65.7 & 61.6 \\
	dog & 79.5 & 71.5 \\
	horse & 84.7 & 66.4 \\
	mbike & 77.2 & 78.5 \\
	person & 91.5 & 92.8 \\
	plant & 53.2 & 56.1 \\
	sheep & 73.3 & 60.0 \\
	sofa & 66.8 & 65.3 \\
	train & 87.7 & 79.2 \\
	tv & 71.7 & 73.7 \\
	\hline
	mAP & 74.9 & 68.4 \\
	\hline
	\end{tabular}
	}
	\label{tab:base}
	\caption{Pre-trained model average precision [UPDATED]}
\end{table}

\section{Selective Search Model result: segmented image training + segmented image testing}
In this phase, we train SVM linear classifier with CNN features extracted from all regions/segments produced by selective search algorithm \cite{uijlings2013}. There are approximately 1.2 million data points coming from 5011 images \cite{pascalvoc2007}, each produce roughly 200-300 regions. To reduce the memory consumption, hard negative mining strategy is used. In the end, the total number of samples used for training is limited to 400,000 samples due to memory constraint.

There are currently two different approaches. The first approach treats all segments from an image with positive label as positive samples. The second approach only treats segments with significant overlap with ground truth bounding box as positive samples.

\subsection{Approach 1}
For the first approach, the positive samples are taken from all segments of all images which have positive label (200-300 images times 200-300 regions so around 40,000 to 70,000 samples). This is, in retrospect, not really correct since many background regions will also be considered as object. But it is interesting to see the result.

Table \ref{tab:ap} shows the comparison between baseline result, pre-trained model, and selective search model. There are some improvement from testing with pre-trained model, but overall, beside the bottle class, the result is still below the baseline result. The result is aggregated using max strategy. The parameter C for SVM training for baseline, pre-trained model, and selective search model are 1.6, 0.8, and 3.2 respectively.

\begin{table}[h]
\centerline{    
	\begin{tabular}{l c c c}
    \hline
    Class & Baseline result & pre-trained model & selective search model \\
    \hline
	bike & \textbf{81.0} & 72.7 & 74.3\\
	bird & \textbf{84.4} & 47.2 & 65.5\\
	boat & \textbf{83.7} & 49.0 & 75.2\\
	bottle & 43.6 & 40.9 & \textbf{45.6}\\
	bus & \textbf{70.9} & 62.6 & 69.0\\
	car & \textbf{84.1} & 83.2 & 79.4\\
	cat & \textbf{82.8} & 71.9 & 75.1\\
	chair & \textbf{61.3} & 55.2 & 51.4\\
	\hline
	mAP (for 8 classes) & \textbf{73.9} & 60.4 & 67.0 \\
    \end{tabular}
}
\caption{PASCAL VOC 2007 Average Precision}
\label{tab:ap}
\end{table}

UPDATED: Table \ref{tab:ap2} shows the new and complete result. Due to time constraint the $C$ parameter is only tested on value 3.2.

\begin{table}[h]
\centerline{    
	\begin{tabular}{l c c c}
       	\hline
        Class & Baseline result & pre-trained model & selective search model 1\\
        \hline
		aero & 87.5 & 66.3 & 80.2\\
		bike & 81.0 & 79.1 & 77.3 \\
		bird & 84.4 & 60.9 & 70.8 \\
		boat & 83.7 & 65.7 & 77.8 \\
		bottle & 43.6 & 44.5 & 48.8 \\
		bus & 70.9 & 68.9 & 64.2 \\
		car & 84.1 & 85.9 & 77.2 \\
		cat & 82.8 & 77.5 & 76.5 \\
		chair & 61.3 & 58.2 & 50.2 \\
		cow & 66.2 & 55.8 & 63.1 \\
		table & 66.5 & 61.6 & 64.6 \\
		dog & 79.4 & 71.5 & 72.4 \\
		horse & 84.9 & 66.4 & 80.3 \\
		mbike & 77.1 & 78.5 & 75.6 \\
		person & 91.7 & 92.8 & 90.3 \\
		plant & 54.2 & 56.1 & 54.3 \\
		sheep & 73.3 & 60.0 & 72.1 \\
		sofa & 66.6 & 65.3 & 57.7 \\
		train & 87.4 & 79.2 & 82.6 \\
		tv & 71.4 & 73.7 & 72.0 \\
		\hline
		mAP & 74.9 & 68.4 & 70.4
    \end{tabular}
}
\caption{PASCAL VOC 2007 Average Precision with pre-train model [UPDATED]}
\label{tab:ap2}
\end{table}

\subsection{Approach 2}
The second approach is to generate training samples based on bounding box annotation. First, the training image is segmented using selective search. Then for each region, the overlapped ratio between the region and object ground truth are computed. If this ratio exceeds certain threshold, then this region is considered as positive samples. A region with zero overlapped area is considered as negative samples.

This procedure is run on the VOC 2007 training data, with threshold 0.3.
Current result shows abysmal performance compared to all previous result. Bug and cause are still being investigated.

\bibliographystyle{plain}
\bibliography{report.bib}

\newpage
\section{Appendix}

\end{document}

